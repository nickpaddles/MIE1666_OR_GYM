This was a final project completed for the university of torontos MIE1666: Mathematical Optmizaiton for Machine Learning course Fall 2024. My partner for this project Mika Nogami (MSc CS 26).

Using the OR-gym Reinforcement Learning library, we reproduced results for a RF model's peformance in a S,s supply chain problem environment. In short, we demonstrated that an RF agent can performa comeptively with stanard optimization methods simply by learning from the training environment.

# Key Achievements include
- Leverage Gemnini to create a wrapper to port legacy code written with Ray 1.x.xx to be compatibel with Ray v2.x.xx
- Tuning the environment to ensure RF agent can withstand stochastic variance in inputs/outputs
- Recreating various heursistc models such as Shrinking Linear Horizon Programming base stock models
